<div align='center'>
  <h3>
    Q-learning ğŸ†šï¸ Sarsa Algorithm 
  </h3>
</div>

O objetivo do projeto Ã© a comparaÃ§Ã£o entre o desempenho de dois algorÃ­timos muito utilizados em Reinforcement Learning, o [QLearning](https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-q-learning) e o [Sarsa](https://towardsdatascience.com/reinforcement-learning-with-sarsa-a-good-alternative-to-q-learning-algorithm-bf35b209e1c). Para demonstrar os diferentes desempenhos, utilizou-se dois ambientes implementados pela biblioteca `gym`, o [TaxiDriver](https://www.gymlibrary.dev/environments/toy_text/taxi/) e o [Cliff Walking](https://www.gymlibrary.dev/environments/toy_text/cliff_walking/)

### ConfiguraÃ§Ãµes âš™ï¸

Instale as bibliotecas necessÃ¡rias utilizando o comando:

```bash

pip install -r requirements.txt

```

Para rodar o projeto siga o padrÃ£o:

```bash

python main.py <ambiente> <algoritimo> <reuse_data>

```

Onde:

- **ambiente** : 'taxi' ou 'cliff'. 

Ambiente onde o algorÃ­timo ocorrerÃ¡.

- **algoritimo**: 'q' ou 'sarsa' ou 'both' . 

AlgorÃ­timo que serÃ¡ utilizado para resolver o problema. 

Caso a opÃ§Ã£o 'both' seja escolhida, ambos os algorÃ­timos rodaram e um grÃ¡fico de sem desempenho comaprativo serÃ¡ criado, caso utilizado essa opÃ§Ã£o, **reuse_data = 0** necessariamente.

- **reuse_data** : '0' ou '1'. 

Utilizar ou nÃ£o um csv existente como valor da **q_table**. 

### TaxiDriver - Desempenho ğŸš•ï¸

### Cliff Walking - Desempenho ğŸ§™â€â™‚ï¸ï¸

### Cliff Walking vs  TaxiDriver - Vantagens e Desvantagens ğŸ“Œï¸ 
